/*
 * @Author: gaoyong gaoyong06@qq.com
 * @Date: 2023-04-21 18:43:56
 * @LastEditors: gaoyong gaoyong06@qq.com
 * @LastEditTime: 2023-04-25 22:20:43
 * @FilePath: \image_hub\spiders\second_page.go
 * @Description: å¾®ä¿¡å…¬ä¼—å·ç¬¬2æ¡å†…å®¹æŠ“å–-èƒŒæ™¯å›¾
 */

package spiders

import (
	"fmt"
	"image_hub/model"
	"image_hub/pkg/utils"
	"net/url"
	"time"

	"github.com/gocolly/colly/v2"
	"github.com/gocolly/colly/v2/queue"
	log "github.com/sirupsen/logrus"
	"github.com/spf13/cast"
)

type secondPage struct {
	Name string
}

// NewSecondPage
func NewSecondPage(name string) Spider {
	return &secondPage{
		Name: name,
	}
}

// è·å–çˆ¬è™«åç§°
func (s *secondPage) GetName() string {
	return s.Name
}

// è®¾ç½®çˆ¬è™«åç§°
func (s *secondPage) SetName(name string) {
	s.Name = name
}

// å‘é˜Ÿåˆ—è¿½æ±‚çˆ¬å–è¯·æ±‚
func (s *secondPage) AddReqToQueue(q *queue.Queue, i interface{}, path string) error {

	pathUrl := fmt.Sprintf("file://%s", path)

	// è§£æ URL
	url, err := url.Parse(pathUrl)
	if err != nil {
		log.Errorf("url.Parse failed. err: %+v\n", err)
		return err
	}

	if _, ok := visited.Get(path); !ok {

		visited.Set(path, true)
		req := &colly.Request{
			URL:    url,
			Method: "GET",
			Ctx:    colly.NewContext(),
		}

		req.Ctx.Put(UrlTypeKey, SecondPage)
		q.AddRequest(req)

	}
	return nil
}

// è§£æå°†çˆ¬å–åˆ°çš„æ•°æ®è‡³ä¸€ä¸ªè§„èŒƒçš„ç»“æ„ä½“ä¸­
// e *colly.HTMLElement æˆ–è€…  *colly.Response
func (s *secondPage) ParseData(q *queue.Queue, i interface{}, baseUrl string) (interface{}, error) {

	// è§£æè¿”å›htmlç»“æœ
	article := &model.TblArticle{}
	var selector string
	var sections []model.Section
	// var err error

	e, ok := i.(*colly.HTMLElement)
	if !ok {
		return nil, fmt.Errorf("invalid type: %T, expected *colly.HTMLElement", i)
	}

	url := e.Request.URL.String()

	// æ–‡ç« æ ‡é¢˜
	selector = "h1#activity-name"
	title := e.ChildText(selector)
	article.Title = title

	// ä½œè€…
	selector = "a#js_name"
	author := e.ChildText(selector)
	article.Author = author

	// å‘å¸ƒæ—¶é—´
	publishTime, _ := utils.GetPublishTime(e.Text)
	article.PublishTime = time.Unix(publishTime, 0)

	fmt.Printf("================ ParseData: url: %s, title: %s\n", url, title)

	// <meta content="http://mp.weixin.qq.com/s?__biz=MjM5NzAyMDIwMA==&amp;mid=2653562471&amp;idx=1&amp;sn=5a209eca9a0c9d92d484dadfa516a807&amp;chksm=bd3ed1208a49583679dddb80f504983511b6bc9d63c89242dd3df68daebd587a78b8fea1afa0#rd"/>
	selector = "meta[property='og:url']"
	ogUrl := e.ChildAttr(selector, "content")
	queryParams, err := utils.GetArticleUrlQueryParams(ogUrl)
	if err != nil {
		log.Errorf("utils.GetArticleUrlQueryParams failed. ogUrl: %s,  err: %+v\n", ogUrl, err)
		return nil, err
	}
	idx := queryParams.Get("idx")
	sn := queryParams.Get("sn")
	biz := queryParams.Get("__biz")
	mid := queryParams.Get("mid")

	article.Idx = cast.ToInt(idx)
	article.Sn = sn
	article.Biz = biz
	article.Mid = cast.ToInt(mid)

	// å…¨éƒ¨æ–‡å­—
	// æ–‡å­—æœ‰ä¸¤ç§
	//  1. ç¬¬ä¸€è¡Œå›¾ç‰‡ä¸‹é¢ä¸€è¡Œæ–‡å­—
	//  2. å…¶ä»–éƒ½æ˜¯ ğŸŒ· ğŸ¤ ğŸŒ·
	selector = ".wxw-img~ span"
	firstText := e.ChildText(selector)

	text := "ğŸŒ· ğŸ¤ ğŸŒ·"

	// æ‰€æœ‰çš„å›¾ç‰‡
	selector = "section section .wxw-img"
	imageUrls := e.ChildAttrs(selector, "src")

	// ç¬¬1è¡Œæ–‡å­—
	// ç¬¬1ç»„9å¼ å›¾
	section1ImageUrls := imageUrls[0:9]

	section1 := model.Section{
		Text:      firstText,
		ImageUrls: section1ImageUrls,
	}

	// ç¬¬2è¡Œæ–‡å­—
	// ç¬¬2ç»„9å¼ å›¾
	section2ImageUrls := imageUrls[9:18]
	section2 := model.Section{
		Text:      text,
		ImageUrls: section2ImageUrls,
	}

	// ç¬¬3ç»„æ–‡å­—
	// ç¬¬3ç»„9å¼ å›¾
	section3ImageUrls := imageUrls[18:27]
	section3 := model.Section{
		Text:      text,
		ImageUrls: section3ImageUrls,
	}

	// ç¬¬4ç»„æ–‡å­—
	// ç¬¬4ç»„9å¼ å›¾
	section4ImageUrls := imageUrls[27:36]
	section4 := model.Section{
		Text:      text,
		ImageUrls: section4ImageUrls,
	}

	// ç¬¬5ç»„æ–‡å­—
	// ç¬¬5ç»„9å¼ å›¾
	section5ImageUrls := imageUrls[36:45]
	section5 := model.Section{
		Text:      text,
		ImageUrls: section5ImageUrls,
	}

	sections = append(sections,
		section1,
		section2,
		section3,
		section4,
		section5,
	)

	article.Title = title
	article.Author = author
	article.PublishTime = time.Unix(publishTime, 0)

	article.Sections = sections
	return article, nil
}

// ä¸šåŠ¡å¤„ç†
// 1. å‘é˜Ÿåˆ—è¿½åŠ è¯·æ±‚
// 2. è§£ææ•°æ®è‡³ç»“æ„ä½“
// 3. ä¿å­˜æ•°æ® æˆ– æ›´æ–°æ•°æ® æˆ– ç»§ç»­ä¸‹ä¸€å±‚çº§çš„è¯·æ±‚
// e *colly.HTMLElement æˆ–è€…  *colly.Response
func (s *secondPage) Process(q *queue.Queue, i interface{}, baseUrl string) error {

	e, ok := i.(*colly.HTMLElement)
	if !ok {
		return fmt.Errorf("%s invalid type: %T, expected *colly.HTMLElement", s.GetName(), i)
	}

	// è§£æè¿”å›jsonç»“æœ
	article, err := s.ParseData(q, e, baseUrl)
	if err != nil {
		log.Errorf("%s ParseData failed. err: %s, url: %+v\n", s.GetName(), err, e.Request.URL.String())
		return err
	}

	// ç±»å‹æ–­è¨€è¿›è¡Œè½¬æ¢
	tblArticle, ok := article.(*model.TblArticle)
	if ok {

		// ä¿å­˜æ•°æ®
		// ä¿å­˜åˆ°æœ¬åœ°article
		sn, err := tblArticle.CreateOrUpdate()
		if err != nil {

			log.Errorf("%s article.CreateOrUpdate failed. err: %s\n", s.GetName(), err)
			fmt.Printf("%s article.CreateOrUpdate failed. err: %s\n", s.GetName(), err)
			return err
		}

		fmt.Printf("%s article.CreateOrUpdate success. sn: %s\n", s.GetName(), sn)
		log.Infof("%s article.CreateOrUpdate success. sn: %s\n", s.GetName(), sn)

		// æŒ‰ç…§å¤šä¸ªsectionä¿å­˜è‡³content_service
		// TODO:è°ƒç”¨content_service APIå®Œæˆæ‰¹é‡å†™å…¥

		return nil

	} else {

		fmt.Printf("%s failed to convert article to tblArticle", s.GetName())
		return fmt.Errorf("%s failed to convert article to tblArticle", s.GetName())
	}
}
